import errno
import math
import os
import random
import shutil
import threading
import time
from datetime import datetime
import socket
import cv2
import gradio as gr
import numpy as np
from PIL import Image, ImageOps
from gradio import components
from skimage import measure
from skimage.morphology import skeletonize
from numpy.ma import cos, sin
from ultralytics import YOLO
from sklearn.neighbors import KDTree
import requests
import subprocess
import ipaddress
import re

import matplotlib.pyplot as plt
import Config as Cf
import Gallery as Gal
import MaxCircle as Mc
import IncircleWide as Iw


def is_file_in_use(file_path):
    """
    æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«å…¶ä»–ç¨‹åºå ç”¨
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
    Returns:
        True: æ–‡ä»¶è¢«å ç”¨
        False: æ–‡ä»¶æœªè¢«å ç”¨
    """
    if not os.path.exists(file_path):
        return False  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå› æ­¤æœªè¢«å ç”¨

    try:
        with open(file_path, "rb+") as f:
            return False
    except IOError as e:
        if e.errno == errno.EACCES:
            return True  # æ–‡ä»¶è¢«å ç”¨
        elif e.errno == errno.ENOENT:
            return False  # æ–‡ä»¶ä¸å­˜åœ¨
        else:
            return True  # å…¶ä»–æœªçŸ¥é”™è¯¯ï¼Œå‡è®¾æ–‡ä»¶è¢«å ç”¨


def copyFiles():
    """
    å°†Yoloå¤„ç†åç”Ÿæˆçš„å›¾ç‰‡è¿›è¡Œè½¬ç§»ï¼Œæ”¾ç½®åˆ°å¯¹åº”æ–‡ä»¶å¤¹ä¸­
    Args:

    Returns:
        new_img: è½¬ç§»åçš„å›¾ç‰‡
    """
    directory = os.path.join(root_dir, "runs/segment")
    folders = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f))]
    folders.sort(key=os.path.getctime)

    newest_folder_path = folders[-1] if folders else None
    if not newest_folder_path:
        return []

    image_files = (os.path.join(root, file) for root, _, files in os.walk(newest_folder_path) for file in files if
                   file.endswith(('.jpg', '.jpeg', '.png', '.gif')))

    new_images = []
    for file_path in image_files:
        try:
            current_time = datetime.now().strftime("%Y%m%d%H%M%S")
            new_file_name = f"{current_time}.jpg"
            destination_path = os.path.join(root_dir, 'result', 'yolo', new_file_name)

            if not is_file_in_use(file_path):
                shutil.copy(file_path, destination_path)
                image = Image.open(destination_path)
                new_images.append(image)
            else:
                print(f"æ–‡ä»¶ {file_path} æ­£åœ¨è¢«å…¶ä»–ç¨‹åºå ç”¨ï¼Œæ— æ³•å¤åˆ¶ã€‚")
        except Exception as e:
            print(f"æ— æ³•æ‰“å¼€å›¾åƒæ–‡ä»¶ {file_path}: {str(e)}")

    # åˆ é™¤æ‰€æœ‰æ–‡ä»¶å¤¹
    for folder in folders:
        shutil.rmtree(folder)

    return new_images


def SVD(points):
    """
    ä½¿ç”¨ å¥‡å¼‚å€¼åˆ†è§£ ï¼ˆSVDï¼‰è®¡ç®—éª¨æ¶çº¿çš„æ³•å‘é‡
    """
    # äºŒç»´ï¼Œä¸‰ç»´å‡é€‚ç”¨
    # äºŒç»´ç›´çº¿ï¼Œä¸‰ç»´å¹³é¢
    pts = points.copy()
    # å¥‡å¼‚å€¼åˆ†è§£
    c = np.mean(pts, axis=0)
    A = pts - c  # shift the points
    A = A.T  # 3*n
    u, s, vh = np.linalg.svd(A, full_matrices=False, compute_uv=True)  # A=u*s*vh
    normal = u[:, -1]

    # æ³•å‘é‡å½’ä¸€åŒ–
    nlen = np.sqrt(np.dot(normal, normal))
    normal = normal / nlen
    # normal æ˜¯ä¸»æ–¹å‘çš„æ–¹å‘å‘é‡ ä¸PCAæœ€å°ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡æ˜¯å‚ç›´å…³ç³»
    # u æ¯ä¸€åˆ—æ˜¯ä¸€ä¸ªæ–¹å‘
    # s æ˜¯å¯¹åº”çš„ç‰¹å¾å€¼
    # c >>> ç‚¹çš„ä¸­å¿ƒ
    # normal >>> æ‹Ÿåˆçš„æ–¹å‘å‘é‡
    return u, s, c, normal


def calcu_dis_from_ctrlpts(ctrlpts):
    if ctrlpts.shape[1] == 4:
        return np.sqrt(np.sum((ctrlpts[:, 0:2] - ctrlpts[:, 2:4]) ** 2, axis=1))
    else:
        return np.sqrt(np.sum((ctrlpts[:, [0, 2]] - ctrlpts[:, [3, 5]]) ** 2, axis=1))


def estimate_normal_for_pos(pos, points, n):
    """
    è®¡ç®—poså¤„çš„æ³•å‘é‡.

    Inputï¼š
    ------
    pos: nx2 ndarray éœ€è¦è®¡ç®—æ³•å‘é‡çš„ä½ç½®.
    points: éª¨æ¶çº¿çš„ç‚¹é›†
    n: ç”¨åˆ°çš„è¿‘é‚»ç‚¹çš„ä¸ªæ•°

    Outputï¼š
    ------
    normals: nx2 ndarray åœ¨posä½ç½®å¤„çš„æ³•å‘é‡.
    """

    # estimate normal vectors at a given point
    pts = np.copy(points)
    tree = KDTree(pts, leaf_size=2)
    idx = tree.query(pos, k=n, return_distance=False, dualtree=False, breadth_first=False)
    # pts = np.concatenate((np.concatenate((pts[0].reshape(1,-1),pts),axis=0),pts[-1].reshape(1,-1)),axis=0)
    normals = []
    for i in range(0, pos.shape[0]):
        pts_for_normals = pts[idx[i, :], :]
        _, _, _, normal = SVD(pts_for_normals)
        normals.append(normal)
    normals = np.array(normals)
    return normals


def estimate_normals(points, n):
    """
    è®¡ç®—pointsè¡¨ç¤ºçš„æ›²çº¿ä¸Šçš„æ¯ä¸€ä¸ªç‚¹æ³•å‘é‡.
    ç­‰åŒäº estimate_normal_for_pos(points,points,n)

    Inputï¼š
    ------
    points: nx2 ndarray æ›²çº¿ç‚¹é›†.
    n: ç”¨åˆ°çš„è¿‘é‚»ç‚¹çš„ä¸ªæ•°

    Outputï¼š
    ------
    normals: nx2 ndarray åœ¨pointsæ›²çº¿ä¸Šçš„æ¯ä¸€å¤„çš„æ³•å‘é‡.
    """

    pts = np.copy(points)
    tree = KDTree(pts, leaf_size=2)
    idx = tree.query(pts, k=n, return_distance=False, dualtree=False, breadth_first=False)
    # pts = np.concatenate((np.concatenate((pts[0].reshape(1,-1),pts),axis=0),pts[-1].reshape(1,-1)),axis=0)
    normals = []
    for i in range(0, pts.shape[0]):
        pts_for_normals = pts[idx[i, :], :]
        _, _, _, normal = SVD(pts_for_normals)
        normals.append(normal)
    normals = np.array(normals)
    return normals


def get_crack_ctrlpts(centers, normals, bpoints, hband=5, vband=2, est_width=0):
    # è·å¾—è£‚çº¹å®½åº¦çš„ä¸»è¦ç®—æ³•
    cpoints = np.copy(centers)
    cnormals = np.copy(normals)

    xmatrix = np.array([[0, 1], [-1, 0]])
    cnormalsx = np.dot(xmatrix, cnormals.T).T  # xè½´çš„æ³•çº¿
    N = cpoints.shape[0]

    interp_segm = []
    widths = []
    for i in range(N):
        try:
            ny = cnormals[i]
            nx = cnormalsx[i]
            tform = np.array([nx, ny])
            bpoints_loc = np.dot(tform, bpoints.T).T
            cpoints_loc = np.dot(tform, cpoints.T).T
            ci = cpoints_loc[i]

            bl_ind = (bpoints_loc[:, 0] - (ci[0] - hband)) * (bpoints_loc[:, 0] - ci[0]) < 0
            br_ind = (bpoints_loc[:, 0] - ci[0]) * (bpoints_loc[:, 0] - (ci[0] + hband)) <= 0
            bl = bpoints_loc[bl_ind]  # å·¦ä¾§è¾¹ç¼˜ç‚¹
            br = bpoints_loc[br_ind]  # å³ä¾§è¾¹ç¼˜ç‚¹

            if est_width > 0:
                # ä¸‹é¢çš„æ•°å€¼ est_width æ˜¯é¢„ä¼°è®¡çš„è£‚ç¼å®½åº¦
                half_est_width = est_width / 2
                # æ‰¾åˆ°å½“å‰ç‚¹çš„å·¦ä¾§è¾¹ç¼˜ç‚¹
                # bltæ•°ç»„ä¸­æ‰€æœ‰ç‚¹çš„ç¬¬äºŒä¸ªåæ ‡å€¼éƒ½å°äºå½“å‰ç‚¹çš„ç¬¬äºŒä¸ªåæ ‡å€¼åŠ ä¸Šé¢„ä¼°å®½åº¦çš„ä¸€åŠ,å…¶ä»–åŒbltæ•°ç»„
                blt = bl[(bl[:, 1] - (ci[1] + half_est_width)) * (bl[:, 1] - ci[1]) < 0]
                blb = bl[(bl[:, 1] - (ci[1] - half_est_width)) * (bl[:, 1] - ci[1]) < 0]
                brt = br[(br[:, 1] - (ci[1] + half_est_width)) * (br[:, 1] - ci[1]) < 0]
                brb = br[(br[:, 1] - (ci[1] - half_est_width)) * (br[:, 1] - ci[1]) < 0]
            else:
                """
                å½“ est_width ä¸º 0 æ—¶ï¼Œä»£ç ä¼šæ ¹æ®è£‚ç¼çš„å·¦å³è¾¹ç¼˜ç‚¹ï¼Œä»¥åŠè£‚ç¼çš„ä¸­å¿ƒç‚¹ï¼Œè®¡ç®—å‡ºè£‚ç¼çš„å®½åº¦ã€‚
                æ ¹æ®è£‚ç¼çš„å·¦å³è¾¹ç¼˜ç‚¹ä»¥åŠè£‚ç¼çš„ä¸­å¿ƒç‚¹è®¡ç®—å‡ºè£‚ç¼çš„å®½åº¦ã€‚
                é¦–å…ˆè®¡ç®—å‡ºå·¦å³è¾¹ç¼˜ç‚¹çš„åæ ‡ï¼Œç„¶åæ ¹æ®è£‚ç¼çš„ä¸­å¿ƒç‚¹è®¡ç®—å‡ºå·¦å³è¾¹ç¼˜ç‚¹ä¸ä¸­å¿ƒç‚¹çš„æ°´å¹³è·ç¦»ã€‚
                æ ¹æ®é¢„è®¾çš„å‚ç›´èŒƒå›´ vbandï¼Œåˆ¤æ–­å·¦å³è¾¹ç¼˜ç‚¹æ˜¯å¦åœ¨å‚ç›´èŒƒå›´å†…ï¼Œå¦‚æœåœ¨ï¼Œåˆ™å°†å…¶ä½œä¸ºè£‚ç¼çš„è¾¹ç¼˜ç‚¹ï¼›å¦åˆ™å°†å…¶å¿½ç•¥ã€‚
                æ ¹æ®å·¦å³è¾¹ç¼˜ç‚¹çš„åæ ‡è®¡ç®—å‡ºè£‚ç¼çš„å®½åº¦ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ widths æ•°ç»„ä¸­ã€‚
                """
                blt = bl[bl[:, 1] > np.mean(bl[:, 1])]
                if np.ptp(blt[:, 1]) > vband:
                    blt = blt[blt[:, 1] > np.mean(blt[:, 1])]

                blb = bl[bl[:, 1] < np.mean(bl[:, 1])]
                if np.ptp(blb[:, 1]) > vband:
                    blb = blb[blb[:, 1] < np.mean(blb[:, 1])]

                brt = br[br[:, 1] > np.mean(br[:, 1])]
                if np.ptp(brt[:, 1]) > vband:
                    brt = brt[brt[:, 1] > np.mean(brt[:, 1])]

                brb = br[br[:, 1] < np.mean(br[:, 1])]
                if np.ptp(brb[:, 1]) > vband:
                    brb = brb[brb[:, 1] < np.mean(brb[:, 1])]

            if blt.size > 0:
                t1 = blt[np.argsort(blt[:, 0])[-1]]
                t2 = brt[np.argsort(brt[:, 0])[0]]

            else:
                # å¦‚æœæ•°ç»„ä¸ºç©ºï¼Œåˆ™è®¾ç½®t1ä¸ºNone
                t1 = None
                t2 = None

            # if blt.size == 0:
            #     interp1 = None
            #     interp2 = None
            # else:
            #     t1 = blt[np.argsort(blt[:, 0])[-1]]
            #     t2 = brt[np.argsort(brt[:, 0])[0]]
            #
            #     b1 = blb[np.argsort(blb[:, 0])[-1]]
            #     b2 = brb[np.argsort(brb[:, 0])[0]]
            #
            #     interp1 = (ci[0] - t1[0]) * ((t2[1] - t1[1]) / (t2[0] - t1[0])) + t1[1]
            #     interp2 = (ci[0] - b1[0]) * ((b2[1] - b1[1]) / (b2[0] - b1[0])) + b1[1]

            # t1 = blt[np.argsort(blt[:, 0])[-1]]
            # t2 = brt[np.argsort(brt[:, 0])[0]]

            b1 = blb[np.argsort(blb[:, 0])[-1]]
            b2 = brb[np.argsort(brb[:, 0])[0]]

            interp1 = (ci[0] - t1[0]) * ((t2[1] - t1[1]) / (t2[0] - t1[0])) + t1[1]
            interp2 = (ci[0] - b1[0]) * ((b2[1] - b1[1]) / (b2[0] - b1[0])) + b1[1]

            if interp1 - ci[1] > 0 and interp2 - ci[1] < 0:
                widths.append([i, interp1 - ci[1], interp2 - ci[1]])

                interps = np.array([[ci[0], interp1], [ci[0], interp2]])

                interps_rec = np.dot(np.linalg.inv(tform), interps.T).T

                interps_rec = interps_rec.reshape(1, -1)[0, :]
                interp_segm.append(interps_rec)
        except Exception as e:
            # print("the %d-th was wrong" % i)
            # traceback.print_exc()
            continue
    interp_segm = np.array(interp_segm)
    widths = np.array(widths)
    # check
    # show_2dpoints([np.array([[ci[0],interp1],[ci[0],interp2]]),np.array([t1,t2,b1,b2]),cpoints_loc,bl,br],[10,20,15,2,2])
    return interp_segm, widths


def load_model(load_model_name, load_model_path=None):
    """
    åŠ è½½æ¨¡å‹
    Args:
        load_model_name: æ¨¡å‹åå­—
        load_model_path: æ¨¡å‹è·¯å¾„

    Returns:
        model: åŠ è½½åçš„æ¨¡å‹
    """
    global model
    if load_model_path is None and root_dir is not None:
        load_model_path = os.path.join(root_dir, 'models', load_model_name)
        model = YOLO(load_model_path)
        print("æ¨¡å‹åŠ è½½å®Œæ¯•")
    elif load_model_path is not None:
        model = YOLO(load_model_path)

    return model


def get_args(conf, threshold, offset, noise, high_precision, simple_line, wide):
    print("conf:", conf)
    print("threshold:", threshold)
    print("offset:", offset)
    print("noise:", noise)
    print("high_precision:", high_precision)
    print("simple_line:", simple_line)
    print("wide:", wide)

    global auto_conf, auto_threshold, auto_offset, auto_noise, auto_high_precision, auto_simple_line, auto_wide

    auto_conf = conf
    auto_threshold = threshold
    auto_offset = offset
    auto_noise = noise
    auto_high_precision = high_precision
    auto_simple_line = simple_line
    auto_wide = wide


def auto_generate():
    global model, pro_img_list
    print("çº¿ç¨‹å¯åŠ¨")
    time.sleep(1)
    stop_event.clear()
    cap = cv2.VideoCapture("http://admin:admin@192.168.14.97:4747/video")
    while not stop_event.is_set():

        hx, img = cap.read()
        img = np.array(img)

        # è·å–åŸå§‹å›¾ç‰‡çš„å®½åº¦å’Œé«˜åº¦
        height, width, _ = img.shape
        img_org = img.copy()

        print("width: ", width)
        print("height: ", height)

        print(width * height)
        # è®¡ç®—ç¼©æ”¾åçš„å®½åº¦å’Œé«˜åº¦
        if width * height > 1920 * 1080:
            img = cv2.resize(img, (int(width * 0.5), int(height * 0.5)))

        # å°†å›¾ç‰‡è½¬æ¢ä¸ºPILå›¾åƒå¯¹è±¡
        img_pil = Image.fromarray(np.uint8(img))

        if not models_check:
            model = load_model(model_name)

        load_path = os.path.join(models_path, model_name)
        if load_path != model_path:
            model = load_model(model_name, load_path)
            Cf.write_models(load_path, model_name)

        else:
            Cf.write_models(os.path.join(models_path, model_name), model_name)

        # è¿›è¡Œæ¨ç†
        model.predict(img_pil, save=True, save_txt=True, imgsz=640, conf=auto_conf)

        copyFiles()

        pro_img_list = process_images(img, auto_noise, auto_threshold, auto_offset, auto_simple_line, auto_wide)
        print("é¢„å¤„ç†å®Œæˆ")

        get_finish_img(img_org, auto_threshold, auto_offset, auto_noise, auto_high_precision, auto_simple_line,
                       auto_wide)
        print("è®¡ç®—å®Œæˆ")
        time.sleep(9)


def output_img():
    global pro_img_list
    time.sleep(5)
    return pro_img_list


def auto_start():
    print("å¼€å§‹è‡ªåŠ¨æ£€æµ‹")
    stop_event.clear()


def auto_stop():
    print("åœæ­¢è‡ªåŠ¨æ£€æµ‹")
    stop_event.set()
    # thread.join()


def file_upload(model_name, conf, threshold, offset, noise_size, wide, simple_line, img=None):
    """
    ä¼ é€’å¤„ç†åå›¾ç‰‡
    Args:
        model_name: æ¨¡å‹åç§°
        img: å¾…å¤„ç†å›¾ç‰‡
        conf: ç½®ä¿¡åº¦
        threshold: å·ç§¯æ ¸å¤§å°
        offset: åç§»é‡
        noise_size: å™ªç‚¹è¿‡æ»¤é˜ˆå€¼
        wide: å®½åº¦è®¡ç®—é˜ˆå€¼
        simple_line: ç®€å•çº¿æ®µæ˜¯å¦å¯ç”¨

    Returns:
        img_original: å¤„ç†åçš„å›¾ç‰‡
    """
    global model, pro_img_list

    # è·å–åŸå§‹å›¾ç‰‡çš„å®½åº¦å’Œé«˜åº¦
    height, width, _ = img.shape

    # è®¡ç®—ç¼©æ”¾åçš„å®½åº¦å’Œé«˜åº¦
    if width * height > 512 * 512:
        img = cv2.resize(img, (int(width * 0.5), int(height * 0.5)))

    # new_width = int(width * 0.5)
    # new_height = int(height * 0.5)
    #
    # # ç¼©æ”¾å›¾ç‰‡
    # img = cv2.resize(img, (new_width, new_height))

    # å°†å›¾ç‰‡è½¬æ¢ä¸ºPILå›¾åƒå¯¹è±¡
    img_pil = Image.fromarray(np.uint8(img))

    if not models_check:
        model = load_model(model_name)

    load_path = os.path.join(models_path, model_name)
    if load_path != model_path:
        model = load_model(model_name, load_path)
        Cf.write_models(load_path, model_name)

    else:
        Cf.write_models(os.path.join(models_path, model_name), model_name)

    # è¿›è¡Œæ¨ç†
    model.predict(img_pil, save=True, save_txt=True, imgsz=640, conf=conf)

    new_images = copyFiles()

    # gray_image = pro_img_list[0]
    # blurred_image = pro_img_list[1]
    # binarization_img = pro_img_list[2]
    # conversion_img = pro_img_list[3]
    # inverted_img = pro_img_list[4]
    #
    # blobs = np.array(inverted_img.copy())
    # blobs = np.where(blobs == 255, 1, blobs)
    # iw, ih = blobs.shape
    # skeleton = skeletonize(blobs)
    #
    # if simple_line:
    #
    #     x, y = np.where(skeleton > 0)
    #     centers = np.hstack((x.reshape(-1, 1), y.reshape(-1, 1)))
    #
    #     normals = estimate_normals(centers, 9)  # ç”¨äºä¼°è®¡æ³•å‘é‡çš„KNN
    #
    #     # æœç´¢è£‚çº¹è½®å»“
    #     contours = measure.find_contours(blobs, 0.8)
    #
    #     bl = contours[0]
    #     br = contours[1]
    #
    #     bpoints = np.vstack((bl, br))
    #
    #     bpixel = np.zeros((iw, ih, 3), dtype=np.uint8)
    #     bpoints = bpoints.astype(np.int64)
    #     bpixel[bpoints[:, 0], bpoints[:, 1], 0] = 255
    #
    #     skeleton_pixel = np.zeros((iw, ih, 3), dtype=np.uint8)
    #     skeleton_pixel[skeleton, 1] = 255
    #
    #     bpixel_and_skeleton = np.copy(bpixel)
    #     bpixel_and_skeleton[skeleton, 1] = 255
    #
    #     fig, ax = plt.subplots(1, 1, figsize=(6, 6))
    #
    #     ax.imshow(bpixel_and_skeleton)
    #
    #     interps, widths = get_crack_ctrlpts(centers, normals, bpoints, hband=2, vband=2, est_width=wide)
    #
    #     interps_show = interps[np.random.choice(interps.shape[0], 240, replace=True), :]  # ç”±äºå¤ªå¤šï¼Œè¿™é‡Œéšæœºé‡‡æ ·240ä¸ªæµ‹é‡ä½ç½®ï¼Œè¿›è¡Œæ˜¾ç¤º
    #
    #     for i in range(interps_show.shape[0]):
    #         ax.plot([interps_show[i, 1], interps_show[i, 3]], [interps_show[i, 0], interps_show[i, 2]], c='c', ls='-',
    #                 lw=1, marker='o', ms=2, mec='c', mfc='c')
    #
    #     fig.tight_layout()
    #
    #     # ä¿å­˜å›¾ç‰‡
    #     plt.savefig("C:/Users/86188/Desktop/Bridge/ultralytics-main/Bridge-Segment/result/output.png")
    #
    #     # è¯»å–ä¿å­˜çš„å›¾ç‰‡ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºndarrayç±»å‹
    #     output_image = Image.open("C:/Users/86188/Desktop/Bridge/ultralytics-main/Bridge-Segment/result/output.png")
    #     output_image = np.array(output_image)
    #
    #     gray_List = [gray_image, blurred_image, binarization_img, conversion_img, inverted_img, output_image,
    #                  skeleton_pixel, bpixel_and_skeleton]
    # else:
    #     gray_List = [gray_image, blurred_image, binarization_img, conversion_img, inverted_img]
    return new_images


def process_images(pen_pro_img, noise_size, threshold, offset, easy_mode_open, width_threshold):
    global pro_img_list
    # è·å–åŸå§‹å›¾ç‰‡çš„å®½åº¦å’Œé«˜åº¦
    height, width, _ = pen_pro_img.shape

    # ç¼©æ”¾å›¾ç‰‡
    pen_pro_img = cv2.resize(pen_pro_img, (int(width * 0.5), int(height * 0.5)))
    # å°†å½©è‰²å›¾åƒè½¬æ¢ä¸ºç°åº¦å›¾åƒ
    gray_image = cv2.cvtColor(pen_pro_img, cv2.COLOR_BGR2GRAY)

    # è®¾ç½®é«˜æ–¯æ»¤æ³¢çš„å‚æ•°
    kernel_size = 11  # é«˜æ–¯æ ¸çš„å¤§å°ï¼Œå¿…é¡»æ˜¯æ­£å¥‡æ•°
    sigma = 2  # é«˜æ–¯æ ¸çš„æ ‡å‡†å·®
    blurred_image = cv2.GaussianBlur(gray_image, (kernel_size, kernel_size), sigma)

    # ä½¿ç”¨è‡ªé€‚åº”å¹³å‡é˜ˆå€¼è¿›è¡ŒäºŒå€¼åŒ–
    binarization_img = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,
                                             threshold, offset)

    conversion_img = binarization_img.copy()

    # å™ªç‚¹è¿‡æ»¤(å°†å°äºä¸€å®šå¤§å°çš„é»‘è‰²åŒºåŸŸè½¬æ¢ä¸ºç™½è‰²)
    contours, hierarchy = cv2.findContours(conversion_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours:
        if cv2.contourArea(cnt) < noise_size:
            x, y, w, h = cv2.boundingRect(cnt)
            cv2.rectangle(conversion_img, (x, y), (x + w, y + h), (255, 255, 255), -1)

    # å°†äºŒå€¼å›¾åƒè½¬æ¢æˆåäºŒå€¼å›¾åƒ
    inverted_img = ImageOps.invert(Image.fromarray(conversion_img.copy()))
    if easy_mode_open:
        easy_img = easy_mode2(inverted_img, pen_pro_img, width_threshold)
        pro_img_list = [gray_image, blurred_image, binarization_img, conversion_img, inverted_img, easy_img]
    else:
        pro_img_list = [gray_image, blurred_image, binarization_img, conversion_img, inverted_img]
    return pro_img_list


# 3. æ‰¾å‡ºè¿™æ¡å‚ç›´çº¿ä¸è½®å»“çš„äº¤ç‚¹ã€‚
def find_intersection(point, direction, contours_img):
    p1 = point - 1000 * direction
    p2 = point + 1000 * direction
    line = cv2.line(np.zeros_like(skeleton), tuple(p1.astype(int)), tuple(p2.astype(int)), 1, 1)
    intersections = cv2.findContours(np.asarray(line & contours_img), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if intersections:
        return intersections[0][0][0], intersections[-1][0][0]
    return None, None


def easy_mode(inverted_img, width_threshold):
    # global pro_img_list
    # print(pro_img_list)
    # gray_image = pro_img_list[0]
    # blurred_image = pro_img_list[1]
    # binarization_img = pro_img_list[2]
    # conversion_img = pro_img_list[3]
    # inverted_img = pro_img_list[4]

    blobs = np.array(inverted_img)
    blobs = np.where(blobs == 255, 1, blobs)
    iw, ih = blobs.shape
    skeleton = skeletonize(blobs)

    x, y = np.where(skeleton > 0)
    centers = np.hstack((x.reshape(-1, 1), y.reshape(-1, 1)))

    normals = estimate_normals(centers, 9)  # ç”¨äºä¼°è®¡æ³•å‘é‡çš„KNN

    # æœç´¢è£‚çº¹è½®å»“
    contours = measure.find_contours(blobs, 0.8)

    bl = contours[0]
    br = contours[1]

    bpoints = np.vstack((bl, br))

    bpixel = np.zeros((iw, ih, 3), dtype=np.uint8)
    bpoints = bpoints.astype(np.int64)
    bpixel[bpoints[:, 0], bpoints[:, 1], 0] = 255

    # skeleton_pixel = np.where(binarization_image_np == False, 0, 255)
    # skeleton_pixel = np.zeros((iw, ih, 3), dtype=np.uint8)
    # skeleton_pixel[skeleton, 1] = 255

    bpixel_and_skeleton = np.copy(bpixel)
    bpixel_and_skeleton[skeleton, 1] = 255

    fig, ax = plt.subplots(1, 1, figsize=(6, 6))

    ax.imshow(bpixel_and_skeleton)

    interps, widths = get_crack_ctrlpts(centers, normals, bpoints, hband=2, vband=2, est_width=width_threshold)

    interps_show = interps[np.random.choice(interps.shape[0], 240, replace=True), :]  # ç”±äºå¤ªå¤šï¼Œè¿™é‡Œéšæœºé‡‡æ ·240ä¸ªæµ‹é‡ä½ç½®ï¼Œè¿›è¡Œæ˜¾ç¤º

    for i in range(interps_show.shape[0]):
        ax.plot([interps_show[i, 1], interps_show[i, 3]], [interps_show[i, 0], interps_show[i, 2]], c='c', ls='-',
                lw=1, marker='o', ms=2, mec='c', mfc='c')

    fig.tight_layout()
    current_time = datetime.now().strftime("%Y%m%d%H%M%S")
    new_file_name = f"{current_time}.jpg"

    # ä¿å­˜å›¾ç‰‡
    easy_path = os.path.join(root_dir, 'result', 'easyMode', new_file_name)
    plt.savefig(easy_path)

    # è¯»å–ä¿å­˜çš„å›¾ç‰‡ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºndarrayç±»å‹
    output_image = cv2.imread(easy_path)

    return output_image


def line_plane_intersection(line1, line2, point, normal):
    # è®¡ç®—å¹³é¢æ³•å‘é‡å’Œå¹³é¢ä¸Šä¸€ç‚¹
    plane_normal = normal / np.sqrt(np.dot(normal, normal))
    plane_point = point - np.dot(point, plane_normal) * plane_normal
    # è®¡ç®—ä¸¤æ¡çº¿æ®µçš„æ–¹å‘å‘é‡
    line1_direction = line1 - line2
    line2_direction = line2 - line1

    # è®¡ç®—å¹³é¢æ³•å‘é‡å’Œä¸¤æ¡çº¿æ®µçš„å‰ç§¯
    cross_product = np.cross(line1_direction, plane_normal)
    # è®¡ç®—äº¤ç‚¹
    t1 = np.dot(plane_point - line1, cross_product) / np.dot(line1_direction, cross_product)
    t2 = np.dot(plane_point - line2, cross_product) / np.dot(line2_direction, cross_product)
    intersection_point = line1 + t1 * line1_direction
    return intersection_point


def easy_mode2(inverted_img, org_img, width_threshold):
    # æŸ¥æ‰¾è½®å»“
    contours_img = inverted_img.copy()
    contours, _ = cv2.findContours(np.asarray(contours_img), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # åˆ›å»ºä¸€ä¸ªå…¨é›¶çš„æ•°ç»„ï¼Œä¸åŸå›¾åƒå…·æœ‰ç›¸åŒçš„å°ºå¯¸
    output_image = np.zeros_like(inverted_img)

    blobs = np.array(inverted_img)
    blobs = np.where(blobs == 255, 1, blobs)
    iw, ih = blobs.shape
    skeleton = skeletonize(blobs)
    x, y = np.where(skeleton > 0)

    skeleton_pixel = np.where(blobs == False, 0, 255)

    # skeleton_pixel = np.zeros((iw, ih, 3), dtype=np.uint8)
    # skeleton_pixel[skeleton, 1] = 255

    points = np.where(skeleton_pixel == 255)
    num_points = int(0.7 * len(points[0]))

    centers = np.hstack((x.reshape(-1, 1), y.reshape(-1, 1)))
    normals = estimate_normals(centers, 9)  # è¿™ä¸ªç”¨äºä¼°è®¡æ³•å‘é‡çš„KNN

    for i in range(centers.size):
        point = centers[i]
        normal = normals[i]
        # è®¡ç®—ä¸å¤–è½®å»“ç›¸äº¤çš„ç‚¹
        intersection_point = None
        for contour in contours:
            contour = np.array(contour)
            if cv2.pointPolygonTest(contour, point, False) > 0:
                # è®¡ç®—äº¤ç‚¹
                intersection_point = line_plane_intersection(contour[0], contour[-1], point, normal)
                break
        if intersection_point is not None:
            # ç»˜åˆ¶çº¿æ®µ
            cv2.line(skeleton_pixel, tuple(point), tuple(intersection_point), (0, 255, 0), 2)

    # x_points = points[1][indices]
    # y_points = points[0][indices]
    # sorted_indices = np.argsort(x_points)
    # x_points = x_points[sorted_indices]
    # y_points = y_points[sorted_indices]
    #
    # # å¯¹äºæ¯ä¸ªç‚¹ï¼Œè®¡ç®—ä¸€æ¡å‚çº¿ï¼Œä½¿å¾—å®ƒä¸éª¨æ¶å¤–è½®å»“ç›¸äº¤
    # for i in range(num_points):
    #     x = x_points[i]
    #     y = y_points[i]
    #     # è®¡ç®—å‚çº¿çš„æ–œç‡å’Œæˆªè·
    #     slope, intercept = np.polyfit([x, x], [0, ih-1], 1)
    #     # è®¡ç®—ä¸éª¨æ¶å¤–è½®å»“ç›¸äº¤çš„ç‚¹
    #     y_intersect = int(intercept)
    #     x_intersect = int(x - intercept / slope)
    #     # ç»˜åˆ¶å‚çº¿
    #     cv2.line(skeleton_pixel, (x, 0), (x, ih-1), (0, 255, 0), 1)
    #     # ç»˜åˆ¶ä¸éª¨æ¶å¤–è½®å»“ç›¸äº¤çš„ç‚¹
    #     cv2.circle(skeleton_pixel, (x_intersect, y_intersect), 3, (0, 0, 255), -1)
    #
    #
    # # åœ¨å…¨é›¶å›¾åƒä¸Šç»˜åˆ¶è½®å»“ï¼Œè®¾ç½®è½®å»“åŒºåŸŸä¸º1
    # cv2.drawContours(skeleton_pixel, contours, -1, (255,0,0))

    return skeleton_pixel


def get_finish_img(img, threshold, offset, noise_size, high_precision, easy_mode_open, width_threshold):
    """
    è·å–è®¡ç®—è£‚ç¼å®½åº¦åçš„å›¾ç‰‡
    Args:
        img: è¾“å…¥å›¾ç‰‡
        threshold: é˜ˆå€¼
        offset: åç§»é‡
        noise_size: å™ªç‚¹é˜ˆå€¼
        high_precision: æ˜¯å¦ä¸ºé«˜ç²¾åº¦æ¨¡å¼
        easy_mode_open: æ˜¯å¦ä¸ºç®€æ˜“æ¨¡å¼
        width_threshold: å®½åº¦é˜ˆå€¼

    Returns:
          è¿”å›å¤„ç†åçš„å›¾ç‰‡
    """
    global finish_data, pro_img_list
    # è·å–åŸå§‹å›¾ç‰‡çš„å®½åº¦å’Œé«˜åº¦
    height, width, _ = img.shape
    # ç¼©æ”¾å›¾ç‰‡
    if width * height > 1920 * 1080:
        min_img = cv2.resize(img, (int(width * 0.5), int(height * 0.5)))
    else:
        min_img = img

    if len(pro_img_list) != 0:
        inverted_img = pro_img_list[4]
    else:
        inverted_img = process_images(img, noise_size, threshold, offset, easy_mode_open, width_threshold)[4]

    finish_img, all_data_list, skeleton_pixel = Mc.max_circle(inverted_img, min_img, high_precision)

    # è·å–å½“å‰æ—¶é—´
    current_time = datetime.now().strftime("%Y%m%d%H%M%S")

    # æ„å»ºæ–°çš„æ–‡ä»¶å
    new_file_name = f"{current_time}.jpg"

    cv2.imwrite(os.path.join(root_dir, 'result', 'inCircle', new_file_name),
                cv2.cvtColor(finish_img, cv2.COLOR_BGR2RGB))

    finish_data = list(map(list, zip(*[all_data_list[0]])))
    if len(list(map(list, zip(*[all_data_list[1]])))) > 0:
        other_data = list(map(list, zip(*[all_data_list[1]])))
    else:
        other_data = [["æ— å…¶ä½™è£‚ç¼æ•°æ®"]]

    width_data_list = [all_data_list[2][0], all_data_list[3][0], other_data, finish_data]
    Cf.width_json(current_time, width_data_list)

    random_data = update_page("åˆå§‹åŒ–")

    pro_img_list = []

    return [finish_img, skeleton_pixel], all_data_list[2][0], all_data_list[3][0], other_data, random_data


def update_page(increase):
    """
    æ›´æ–°è¡¨æ ¼æ•°æ®çš„å‡½æ•°
    Args:
        increase: æŒ‡ä»¤

    Returns:
        finish_data: è¡¨æ ¼æ•°æ®
    """
    global page
    total_pages = (len(finish_data) + 4) // 5
    if increase == "åˆå§‹åŒ–":
        page = 0
    elif increase == "ä¸Šä¸€é¡µ" and page != 0:
        page -= 1
    elif increase == "ä¸‹ä¸€é¡µ" and page < total_pages - 1:
        start = page * 5
        end = start + 5
        if len(finish_data[start:end]) < 5:
            return finish_data[start:end]
        page += 1

    start = page * 5
    end = start + 5
    return finish_data[start:end]


def get_page_data(img_list, page_num, items_per_page=20):
    """
    è·å–é¡µé¢ä¿¡æ¯
    Args:
        img_list: å›¾ç‰‡åˆ—è¡¨
        page_num: é¡µç 
        items_per_page: æ¯é¡µå±•ç¤ºæ•°é‡

    Returns:
        img_list: éœ€è¦æ˜¾ç¤ºçš„å›¾ç‰‡
    """
    start = page_num * items_per_page
    end = start + items_per_page
    return img_list[start:end]


def update_img_list(increase):
    """
    æ›´æ–°å›¾ç‰‡åˆ—è¡¨
    Args:
        increase: æ›´æ–°å›¾ç‰‡çš„æ–¹æ³•
    Returns:
        page_data: æ›´æ–°åçš„å›¾ç‰‡åˆ—è¡¨
        page_num: å½“å‰é¡µç 
        delete: åˆ é™¤æŒ‰é’®çš„çŠ¶æ€
    """
    global img_page_list, pageNum

    total_pages = (len(img_page_list) + 19) // 20  # è®¡ç®—æ€»é¡µæ•°

    def init_page():
        return 0

    def last_page():
        return total_pages - 1

    def current_page():
        return pageNum

    def prev_page():
        return max(0, pageNum - 1)

    def next_gallery_page():
        if pageNum < total_pages - 1:
            return pageNum + 1
        return pageNum

    def refresh_page():
        global img_page_list
        img_page_list = Gal.initialization_img_list('yolo')
        return pageNum

    actions = {
        "åˆå§‹åŒ–": init_page,
        "é¦–é¡µ": init_page,
        "åˆ·æ–°": refresh_page,
        "å°¾é¡µ": last_page,
        "è·³è½¬": current_page,
        "ä¸Šä¸€é¡µ": prev_page,
        "ä¸‹ä¸€é¡µ": next_gallery_page
    }

    pageNum = actions[increase]()
    page_data = get_page_data(img_page_list, pageNum)

    return page_data, pageNum, delete.update(visible=False)


def get_page_boundaries(page_num, items_per_page, total_items):
    """
    è·å–å½“å‰é¡µçš„èµ·å§‹å’Œç»“æŸä½ç½®
    Args:
        page_num: å½“å‰é¡µç 
        items_per_page: æ¯é¡µæ˜¾ç¤ºçš„å›¾ç‰‡æ•°é‡
        total_items: å›¾ç‰‡æ€»æ•°

    Returns:
        start: èµ·å§‹ä½ç½®
        end: ç»“æŸä½ç½®
        page_num: å½“å‰é¡µç 
    """
    start = page_num * items_per_page
    end = start + items_per_page

    if start >= total_items:
        page_num = (total_items - 1) // items_per_page
        start = page_num * items_per_page
        end = start + items_per_page

    return start, end, page_num


def on_page_num_change(event, items_per_page=20):
    """
    æ›´æ–°å½“å‰é¡µç 
    Args:
        event: å½“å‰é¡µç 
        items_per_page: æ¯é¡µæ˜¾ç¤ºçš„å›¾ç‰‡æ•°é‡

    Returns:
        img_page_list: æ›´æ–°åçš„å›¾ç‰‡åˆ—è¡¨
        page_num: å½“å‰é¡µç 
        delete: åˆ é™¤æŒ‰é’®æ˜¯å¦å¯è§
    """
    global pageNum
    pageNum = max(int(event), 0)  # ä¿è¯pageNuméè´Ÿ

    start, end, pageNum = get_page_boundaries(pageNum, items_per_page, len(img_page_list))

    return img_page_list[start:end], pageNum, delete.update(visible=False)


def on_select_img(gallery_list_now, event_data: gr.SelectData):
    """
    è¢«é€‰æ‹©çš„å›¾ç‰‡
    Args:
        gallery_list_now: å›¾ç‰‡åˆ—è¡¨
        event_data: å½“å‰é€‰ä¸­çš„å›¾ç‰‡

    Returns:
          delete æŒ‰é’®çŠ¶æ€
    """
    global img_name, gallery_list
    gallery_list = gallery_list_now
    filename = os.path.basename(gallery_list_now[event_data.index]["name"])
    img_name = filename

    return delete.update(visible=True)


def delete_img(img_name_delete, file_path):
    """
    åˆ é™¤å›¾ç‰‡
    Args:
        img_name_delete: å›¾ç‰‡åç§°
        file_path: å›¾ç‰‡è·¯å¾„

    Returns:
        img_page_list: åˆ é™¤åçš„å›¾ç‰‡åˆ—è¡¨
    """
    global img_page_list

    # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼æ¥è¿‡æ»¤æ‰ç›®æ ‡å­—ç¬¦ä¸²
    filtered_file_paths = [path for path in img_page_list if not path.endswith(img_name_delete)]

    start = pageNum * 20
    end = start + 20
    img_page_list = filtered_file_paths

    os.remove(os.path.join(file_path, 'yolo', img_name_delete))
    return img_page_list[start:end]


def is_private_ip(ip):
    # ç§ç½‘IPåœ°å€èŒƒå›´
    private_ranges = [
        ('10.0.0.0', '10.255.255.255'),
        ('172.16.0.0', '172.31.255.255'),
        ('192.168.0.0', '192.168.255.255')
    ]

    # å°†IPåœ°å€è½¬æ¢ä¸ºæ•´æ•°
    ip_int = int(ip.split('.')[0]) << 24 | int(ip.split('.')[1]) << 16 | int(ip.split('.')[2]) << 8 | int(
        ip.split('.')[3])

    # åˆ¤æ–­IPåœ°å€æ˜¯å¦åœ¨ç§ç½‘IPåœ°å€èŒƒå›´å†…
    for start, end in private_ranges:
        start_int = int(start.split('.')[0]) << 24 | int(start.split('.')[1]) << 16 | int(
            start.split('.')[2]) << 8 | int(start.split('.')[3])
        end_int = int(end.split('.')[0]) << 24 | int(end.split('.')[1]) << 16 | int(end.split('.')[2]) << 8 | int(
            end.split('.')[3])
        if start_int <= ip_int <= end_int:
            return False
    print("IPç½‘æ®µä½äºå…¬ç½‘ç½‘æ®µå†…ï¼Œè¿›è¡Œå¯ç”¨...")
    return True


def has_public_ip(port):
    address = socket.getaddrinfo(socket.gethostname(), None)
    print("æ£€ç´¢åˆ°æœ¬æœºIPï¼Œæä¾›è®¿é—®åœ°å€")
    pattern = r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'
    for addr in address:

        match = re.search(pattern, addr[4][0])
        if match:
            if is_private_ip(match.group(1)):
                print("æ£€ç´¢åˆ°å…¬ç½‘IPï¼Œè¿›è¡Œå¯ç”¨...")
                print(f"Running on public URL:  http://{match.group(1)}:{port}")
            else:
                print(f"http://{match.group(1)}:{port}")
    return False


if __name__ == '__main__':
    Cf.inspect_config_file()

    # è·å–å½“å‰è„šæœ¬æ–‡ä»¶çš„æ ¹ç›®å½•
    root_dir = os.path.dirname(os.path.abspath(__file__))
    models_path = os.path.join(root_dir, 'models')
    page = 0
    pageNum = 0
    auto = False
    model = None
    img_name = None
    gray_img_total = None
    finish_data = []
    gallery_list = []
    pro_img_list = []
    stop_event = threading.Event()
    stop_event.set()
    # è‡ªåŠ¨ç›‘æµ‹æ¨¡å¼å…¨å±€å˜é‡
    auto_conf, auto_threshold, auto_offset, auto_noise, auto_high_precision, auto_simple_line, auto_wide = 0.6, 161, 31, 300, False, False, 60

    models_check, model_path = Cf.check_models()
    model_name = os.path.basename(model_path)
    if models_check:
        load_model(model_name, model_path)
    with gr.Blocks() as demo:
        folder_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'models')
        result_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'result')
        # è·å–æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶åˆ—è¡¨
        file_list = os.listdir(folder_path)

        # åˆå§‹åŒ–å›¾ç‰‡åˆ—è¡¨
        img_page_list = Gal.initialization_img_list('yolo')
        img_list = img_page_list[0:20]

        in_circle_list = Iw.initialization()

        # åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ç»„
        options = [file for file in file_list if os.path.isfile(os.path.join(folder_path, file))]

        if models_check:
            model_input = components.Dropdown(choices=options, value=model_name, label="é€‰æ‹©æ¨¡å‹æ–‡ä»¶")
        else:
            # åˆ›å»ºä¸€ä¸ªæ–‡ä»¶è¾“å…¥ç»„ä»¶
            model_input = components.Dropdown(choices=options, label="é€‰æ‹©æ¨¡å‹æ–‡ä»¶")

        with gr.Accordion(label="è¯†åˆ«å‚æ•°", open=False):
            conf = gr.Slider(label="ç½®ä¿¡åº¦", minimum=0, maximum=1, value=0.6)
            threshold = gr.Slider(label="å·ç§¯æ ¸å¤§å°", minimum=0, maximum=255, value=161)
            offset = gr.Slider(label="åç§»å€¼å¤§å°", minimum=0, maximum=100, value=31)
            noise = gr.Slider(label="å™ªç‚¹è¿‡æ»¤é˜ˆå€¼", minimum=0, maximum=500, value=300)
            wide = gr.Slider(label="å®½åº¦è®¡ç®—é˜ˆå€¼", minimum=0, maximum=500, value=60)

        with gr.Accordion(label="æ£€æµ‹æ¨¡å¼", open=False):
            # auto_camera = gr.Checkbox(label="è‡ªåŠ¨ç›‘æµ‹æ¨¡å¼", value=False)
            simple_line = gr.Checkbox(label="å•è£‚ç¼æ¨¡å¼", value=False)
            high_precision = gr.Checkbox(label="é«˜ç²¾åº¦æ¨¡å¼(å¤§å¹…å¢åŠ è®¡ç®—æ—¶é—´)", value=False)

        with gr.Tab("æ¨ç†"):
            # Blocksç‰¹æœ‰ç»„ä»¶ï¼Œè®¾ç½®æ‰€æœ‰å­ç»„ä»¶æŒ‰å‚ç›´æ’åˆ—
            # å‚ç›´æ’åˆ—æ˜¯é»˜è®¤æƒ…å†µï¼Œä¸åŠ ä¹Ÿæ²¡å…³ç³»
            with gr.Row():
                img_input = components.Image(label="é€‰æ‹©å›¾ç‰‡æ–‡ä»¶")
                gallery = gr.Gallery(
                    label="æ¨ç†ç»“æœ",
                    columns=1,
                    rows=1,
                    preview=True
                )

                filtered_image = gr.Gallery(
                    label="é«˜æ–¯æ¨¡ç³Š",
                    columns=1,
                    rows=1,
                    preview=True
                )

                wide_gallery = gr.Gallery(
                    label="è£‚ç¼å®½åº¦ç»“æœ",
                    columns=1,
                    rows=1,
                    preview=True
                )
            with gr.Accordion(label="è£‚ç¼å®½åº¦è®¡ç®—ç»“æœ", open=False):
                with gr.Row():
                    max_wide_label = gr.Textbox(label="æœ€å¤§å®½åº¦", value="0")
                    avg_wide_label = gr.Textbox(label="å¹³å‡å®½åº¦", value="0")

                with gr.Row():
                    second_label = gr.Dataframe(headers=["æ¬¡è¦è£‚ç¼æœ€å¤§å®½åº¦"], datatype=["number"], max_rows=5,
                                                overflow_row_behaviour="paginate")
                    with gr.Column():
                        random_label = gr.Dataframe(headers=["éšæœºå–æ ·å®½åº¦"], datatype=["number"])
                        with gr.Row():
                            before_page = "ä¸Šä¸€é¡µ"
                            next_page = "ä¸‹ä¸€é¡µ"
                            before_data = gr.Button(before_page)
                            next_data = gr.Button(next_page)

            before_data.click(fn=lambda: update_page(before_page), outputs=[random_label])
            next_data.click(fn=lambda: update_page(next_page), outputs=[random_label])

            greet_btn = gr.Button("æäº¤")

            greet_btn.click(fn=file_upload, inputs=[
                model_input,
                conf,
                threshold,
                offset,
                noise,
                wide,
                simple_line,
                img_input], outputs=[gallery])

            greet_btn.click(fn=process_images, inputs=[img_input, noise, threshold, offset, simple_line, wide],
                            outputs=[filtered_image])

            greet_btn.click(fn=get_finish_img, inputs=[
                img_input,
                threshold,
                offset,
                noise,
                high_precision,
                simple_line,
                wide], outputs=[wide_gallery, max_wide_label, avg_wide_label, second_label, random_label])

        with gr.Tab("è‡ªç›‘æ§æ¨¡å¼"):
            with gr.Row():
                run_button = gr.Button("å¯åŠ¨")
                stop_button = gr.Button("åœæ­¢")
            with gr.Row():
                out_img = gr.Gallery(
                    label="é¢„å¤„ç†å›¾ç‰‡",
                    columns=1,
                    rows=1,
                    preview=True
                )

            thread = threading.Thread(target=auto_generate)

            run_button.click(fn=get_args, inputs=[conf, threshold, offset, noise, high_precision, simple_line, wide])
            run_button.click(fn=thread.start)
            run_button.click(fn=output_img, outputs=[out_img])
            stop_button.click(fn=auto_stop)
        with gr.Tab("å›¾åº“æµè§ˆå™¨"):
            # Blocksç‰¹æœ‰ç»„ä»¶ï¼Œè®¾ç½®æ‰€æœ‰å­ç»„ä»¶æŒ‰æ°´å¹³æ’åˆ—

            with gr.Row():
                with gr.Tab("è¯†åˆ«ç»“æœ"):
                    with gr.Row():
                        first_page = gr.Button("é¦–é¡µ")
                        beforeButton = gr.Button("ä¸Šä¸€é¡µ")
                        getPageNum = gr.Number(label="é¡µç ", interactive=True)
                        refresh = gr.Button("ğŸ”„")
                        nextButton = gr.Button("ä¸‹ä¸€é¡µ", )
                        end_page = gr.Button("å°¾é¡µ")
                    inference_results = gr.Gallery(label="æ¨ç†ç»“æœ", value=img_list, columns=5, object_fit='contain')
                    delete = gr.Button("åˆ é™¤", visible=False)
                with gr.Tab("å®½åº¦è®¡ç®—"):
                    with gr.Row():
                        block2 = Iw.inCircleWide()

            first_page.click(fn=lambda: update_img_list("é¦–é¡µ"), outputs=[inference_results, getPageNum, delete])
            beforeButton.click(fn=lambda: update_img_list("ä¸Šä¸€é¡µ"), outputs=[inference_results, getPageNum, delete])
            nextButton.click(fn=lambda: update_img_list("ä¸‹ä¸€é¡µ"), outputs=[inference_results, getPageNum, delete])
            end_page.click(fn=lambda: update_img_list("å°¾é¡µ"), outputs=[inference_results, getPageNum, delete])
            refresh.click(fn=lambda: update_img_list("åˆ·æ–°"), outputs=[inference_results, getPageNum, delete])
            getPageNum.submit(fn=on_page_num_change, inputs=[getPageNum],
                              outputs=[inference_results, getPageNum, delete])

            inference_results.select(fn=on_select_img, inputs=[inference_results],
                                     outputs=[delete])
            delete.click(fn=lambda: delete_img(img_name, result_path), outputs=[inference_results])

    port = 7860
    has_public_ip(port)
    demo.launch(server_name="0.0.0.0", server_port=port)
